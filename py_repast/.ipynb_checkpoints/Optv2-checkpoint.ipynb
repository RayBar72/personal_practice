{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0103180",
   "metadata": {},
   "source": [
    "# Task 0 - Normalization Constants\n",
    "Write the function `def normalization_constants(X):` that calculates the normalization (standardization) constants of a matrix:\n",
    "- `X` is the numpy.ndarray of shape `(m, nx)` to normalize\n",
    "    - `m` is the number of data points\n",
    "    - `nx` is the number of features\n",
    "- Returns: the mean and standard deviation of each feature, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0ce4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalization_constants(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    s = np.std(X, axis=0)\n",
    "    return mu, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab6ffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11961603  2.08201297 -3.59232261]\n",
      "[2.01576449 1.034667   9.52002619]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68ba08",
   "metadata": {},
   "source": [
    "# Task 1 - Normalize\n",
    "Write the function `def normalize(X, m, s):` that normalizes (standardizes) a matrix:\n",
    "- `X` is the `numpy.ndarray` of shape `(d, nx)` to normalize\n",
    "    - `d` is the number of data points\n",
    "    - `nx` is the number of features\n",
    "- `m` is a `numpy.ndarray` of shape `(nx,)` that contains the mean of all features of `X`\n",
    "- `s` is a `numpy.ndarray` of shape `(nx,)` that contains the standard deviation of all features of `X`\n",
    "- Returns: The normalized `X` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b8c4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(X, m, s):\n",
    "    Z = (X - m) / s\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a346a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.52810469   3.8831507   -6.69181838]\n",
      " [  0.80031442   0.65224094  -5.39379178]\n",
      " [  1.95747597   0.729515     7.99659596]\n",
      " [  4.4817864    2.96939671   3.55263731]\n",
      " [  3.73511598   0.82687659   3.40131526]\n",
      " [ -1.95455576   3.94362119 -19.16956044]\n",
      " [  1.90017684   1.58638102  -3.24326124]\n",
      " [ -0.30271442   1.25254519 -10.38030909]\n",
      " [ -0.2064377    3.92294203  -0.20075401]\n",
      " [  0.821197     3.48051479  -3.9815039 ]]\n",
      "[[ 1.69091612  1.74078977 -0.32557639]\n",
      " [ 0.33768746 -1.38186686 -0.18922943]\n",
      " [ 0.91174338 -1.3071819   1.21732003]\n",
      " [ 2.16402779  0.85765153  0.75051893]\n",
      " [ 1.79361228 -1.21308245  0.73462381]\n",
      " [-1.02897526  1.79923417 -1.63625998]\n",
      " [ 0.88331787 -0.47902557  0.03666601]\n",
      " [-0.20951378 -0.80167608 -0.71302183]\n",
      " [-0.1617519   1.77924787  0.35625623]\n",
      " [ 0.34804709  1.35164437 -0.04088028]]\n",
      "[ 2.44249065e-17 -4.99600361e-16  1.46549439e-16]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(X[:10])\n",
    "    X = normalize(X, m, s)\n",
    "    print(X[:10])\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3eac39",
   "metadata": {},
   "source": [
    "# Task 2 - Shuffle Data\n",
    "Write the function `def shuffle_data(X, Y):` that shuffles the data points in two matrices the same way:\n",
    "- `X` is the first `numpy.ndarray` of shape `(m, nx)` to shuffle\n",
    "    - `m` is the number of data points\n",
    "    - `nx` is the number of features in `X`\n",
    "- `Y` is the second `numpy.ndarray` of shape `(m, ny)` to shuffle\n",
    "    - `m` is the same number of data points as in `X`\n",
    "    - `ny` is the number of features in `Y`\n",
    "- Returns: the shuffled `X` and `Y` matrices\n",
    "\n",
    "Hint: you should use `numpy.random.permutation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a47b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def shuffle_data(X, Y):\n",
    "    m = X.shape[0]\n",
    "    rand = np.random.permutation(m)\n",
    "    return X[rand], Y[rand]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d23d15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6]\n",
      " [ 1  2]\n",
      " [ 3  4]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "[[15 16]\n",
      " [11 12]\n",
      " [13 14]\n",
      " [17 18]\n",
      " [19 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = np.array([[1, 2],\n",
    "                [3, 4],\n",
    "                [5, 6],\n",
    "                [7, 8], \n",
    "                [9, 10]])\n",
    "    Y = np.array([[11, 12],\n",
    "                [13, 14],\n",
    "                [15, 16],\n",
    "                [17, 18],\n",
    "                [19, 20]])\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X_shuffled, Y_shuffled = shuffle_data(X, Y)\n",
    "\n",
    "    print(X_shuffled)\n",
    "    print(Y_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae8751",
   "metadata": {},
   "source": [
    "# Task - Mini-Batch\n",
    "Write the function `def train_mini_batch(X_train, Y_train, X_valid, Y_valid, batch_size=32, epochs=5, load_path=\"/tmp/model.ckpt\", save_path=\"/tmp/model.ckpt\"):` that trains a loaded neural network model using mini-batch gradient descent:\n",
    "\n",
    "* `X_train` is a `numpy.ndarray` of shape `(m, 784)` containing the training data\n",
    "  * `m` is the number of data points\n",
    "  * `784` is the number of input features\n",
    "* `Y_train` is a one-hot `numpy.ndarray` of shape `(m, 10)` containing the training labels\n",
    "  * `10` is the number of classes the model should classify\n",
    "* `X_valid` is a `numpy.ndarray` of shape `(m, 784)` containing the validation data\n",
    "* `Y_valid` is a one-hot `numpy.ndarray` of shape `(m, 10)` containing the validation labels\n",
    "* `batch_size` is the number of data points in a batch\n",
    "* `epochs` is the number of times the training should pass through the whole dataset\n",
    "* `load_path` is the path from which to load the model\n",
    "* `save_path` is the path to where the model should be saved after training\n",
    "* Returns: the path where the model was saved\n",
    "* Your training function should allow for a smaller final batch (a.k.a. use the entire training set)\n",
    "1. import meta graph and restore session\n",
    "2. Get the following tensors and ops from the collection restored\n",
    "  * `x` is a placeholder for the input data\n",
    "  * `y` is a placeholder for the labels\n",
    "  * `accuracy` is an op to calculate the accuracy of the model\n",
    "  * `loss` is an op to calculate the cost of the model\n",
    "  * `train_op` is an op to perform one pass of gradient descent on the model\n",
    "3. loop over epochs:\n",
    "  * shuffle data\n",
    "  * loop over the batches:\n",
    "    * get `X_batch` and `Y_batch` from data\n",
    "    * train your model\n",
    "4. Save session\n",
    "* You should use `shuffle_data = __import__('2-shuffle_data').shuffle_data`\n",
    "* Before the first epoch and after every subsequent epoch, the following should be printed:\n",
    "  * `After {epoch} epochs:` where `{epoch}` is the current epoch\n",
    "  * `\\tTraining Cost: {train_cost}` where `{train_cost}` is the cost of the model on the entire training set\n",
    "  * `\\tTraining Accuracy: {train_accuracy}` where `{train_accuracy}` is the accuracy of the model on the entire training set\n",
    "  * `\\tValidation Cost: {valid_cost}` where `{valid_cost}` is the cost of the model on the entire validation set\n",
    "  * `\\tValidation Accuracy: {valid_accuracy}` where `{valid_accuracy}` is the accuracy of the model on the entire validation set\n",
    "* After every 100 steps gradient descent within an epoch, the following should be printed:\n",
    "  * `\\tStep {step_number}:` where `{step_number}` is the number of times gradient descent has been run in the current epoch\n",
    "  * `\\t\\tCost: {step_cost}` where `{step_cost}` is the cost of the model on the current mini-batch\n",
    "  * `\\t\\tAccuracy: {step_accuracy}` where `{step_accuracy}` is the accuracy of the model on the current mini-batch\n",
    "  * Advice: the function `range` can help you to handle this loop inside your dataset by using `batch_size` as step value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e584dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "def train_mini_batch(X_train, Y_train, X_valid, Y_valid, batch_size=32,\n",
    "                     epochs=5, load_path=\"/tmp/model.ckpt\", save_path=\"/tmp/model.ckpt\"):\n",
    "    with tf.Session() as sess:\n",
    "#         Primero se importa la gráfica\n",
    "        saved = tf.train.import_meta_graph('{}.meta'.format(load_path))\n",
    "#         Luego se restaura la sesión\n",
    "        saved.restore(sess, load_path)\n",
    "#         Se estan cargando los placeholders\n",
    "        x = tf.get_collection('x')[0]\n",
    "        y = tf.get_collection('y')[0]\n",
    "        accuracy = tf.get_collection('accuracy')[0]\n",
    "        loss = tf.get_collection('loss')[0]\n",
    "        train_op = tf.get_collection('train_op')[0]\n",
    "#         Definiendo shuffle\n",
    "        m = X_train.shape[0]\n",
    "        if m % batch_size == 0:\n",
    "            min_batch = m / batch_size\n",
    "        else:\n",
    "            min_batch = int(m / batch_size) + 1\n",
    "#         Generando epochs y mensaje\n",
    "        for epoch in range(epochs + 1):\n",
    "#             Se agrega un epoch para imprimir el resultado final\n",
    "            dt = {x: X_train, y: Y_train}\n",
    "            dv = {x: X_valid, y: Y_valid}\n",
    "            train_cost = sess.run(loss, feed_dict=dt)\n",
    "            train_accuracy = sess.run(accuracy, feed_dict=dt)\n",
    "            valid_cost = sess.run(loss, feed_dict=dv)\n",
    "            valid_accuracy = sess.run(accuracy, feed_dict=dv)\n",
    "            print('After {} epochs:'.format(epoch))\n",
    "            print('\\tTraining Cost: {}'.format(train_cost))\n",
    "            print('\\tTraining Accuracy: {}'.format(train_accuracy))\n",
    "            print('\\tValidation Cost: {}'.format(valid_cost))\n",
    "            print('\\tValidation Accuracy: {}'.format(valid_accuracy))\n",
    "            if epoch < epochs:\n",
    "                Xsh, Ysh = shuffle_data(X_train, Y_train)\n",
    "                for i in range(min_batch):\n",
    "                    a_0 = i * batch_size\n",
    "                    a_1 = a_0 + batch_size\n",
    "                    if m > a_1:\n",
    "                        a_1 = m\n",
    "                    X_mb = Xsh[a_0:a_1]\n",
    "                    Y_mb = Ysh[a_0:a_1]\n",
    "                    dt = {x: X_mb, y: Y_mb}\n",
    "                    train = sess.run(train_op, feed_dict=dt)\n",
    "                    if (i + 1) % 100 == 0 and i != 0:\n",
    "                        step_cost = sess.run(loss, feed_dict=dt)\n",
    "                        step_accuracy = sess.run(accuracy, feed_dict=dt)\n",
    "                        print('\\tStep {}:'.format(i + 1))\n",
    "                        print('\\t\\tCost: {}'.format(step_cost))\n",
    "                        print('\\t\\tAccuracy: {}'.format(step_accuracy))\n",
    "        return saved.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a00f42f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./graph.ckpt\n",
      "After 0 epochs:\n",
      "\tTraining Cost: 2.8232288360595703\n",
      "\tTraining Accuracy: 0.08726000040769577\n",
      "\tValidation Cost: 2.810532331466675\n",
      "\tValidation Accuracy: 0.08640000224113464\n",
      "\tStep 100:\n",
      "\t\tCost: 0.8404947519302368\n",
      "\t\tAccuracy: 0.7824564576148987\n",
      "\tStep 200:\n",
      "\t\tCost: 0.6099883317947388\n",
      "\t\tAccuracy: 0.8393381237983704\n",
      "\tStep 300:\n",
      "\t\tCost: 0.5182862281799316\n",
      "\t\tAccuracy: 0.8596903681755066\n",
      "\tStep 400:\n",
      "\t\tCost: 0.46630072593688965\n",
      "\t\tAccuracy: 0.8722872734069824\n",
      "\tStep 500:\n",
      "\t\tCost: 0.43379902839660645\n",
      "\t\tAccuracy: 0.8808474540710449\n",
      "\tStep 600:\n",
      "\t\tCost: 0.4101600646972656\n",
      "\t\tAccuracy: 0.8861247897148132\n",
      "\tStep 700:\n",
      "\t\tCost: 0.39346444606781006\n",
      "\t\tAccuracy: 0.8900550007820129\n",
      "\tStep 800:\n",
      "\t\tCost: 0.3755631446838379\n",
      "\t\tAccuracy: 0.8942370414733887\n",
      "\tStep 900:\n",
      "\t\tCost: 0.36094605922698975\n",
      "\t\tAccuracy: 0.8985022902488708\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.3509767949581146\n",
      "\t\tAccuracy: 0.9002329111099243\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.3412742018699646\n",
      "\t\tAccuracy: 0.9029800295829773\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.32486411929130554\n",
      "\t\tAccuracy: 0.9066368341445923\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.31622403860092163\n",
      "\t\tAccuracy: 0.9089183807373047\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.3007860481739044\n",
      "\t\tAccuracy: 0.9118883609771729\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.28628024458885193\n",
      "\t\tAccuracy: 0.9168307185173035\n",
      "After 1 epochs:\n",
      "\tTraining Cost: 0.33068472146987915\n",
      "\tTraining Accuracy: 0.9063400030136108\n",
      "\tValidation Cost: 0.3039607107639313\n",
      "\tValidation Accuracy: 0.9129999876022339\n",
      "\tStep 100:\n",
      "\t\tCost: 0.3119071125984192\n",
      "\t\tAccuracy: 0.9113853573799133\n",
      "\tStep 200:\n",
      "\t\tCost: 0.30465975403785706\n",
      "\t\tAccuracy: 0.9133663177490234\n",
      "\tStep 300:\n",
      "\t\tCost: 0.30000734329223633\n",
      "\t\tAccuracy: 0.9144737124443054\n",
      "\tStep 400:\n",
      "\t\tCost: 0.2965649962425232\n",
      "\t\tAccuracy: 0.9156370759010315\n",
      "\tStep 500:\n",
      "\t\tCost: 0.29125356674194336\n",
      "\t\tAccuracy: 0.9166079163551331\n",
      "\tStep 600:\n",
      "\t\tCost: 0.2879939079284668\n",
      "\t\tAccuracy: 0.9178775548934937\n",
      "\tStep 700:\n",
      "\t\tCost: 0.284801185131073\n",
      "\t\tAccuracy: 0.9185726642608643\n",
      "\tStep 800:\n",
      "\t\tCost: 0.2833675742149353\n",
      "\t\tAccuracy: 0.9195317625999451\n",
      "\tStep 900:\n",
      "\t\tCost: 0.2789592146873474\n",
      "\t\tAccuracy: 0.9216277599334717\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.27192726731300354\n",
      "\t\tAccuracy: 0.9228593707084656\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.2667166292667389\n",
      "\t\tAccuracy: 0.9250943660736084\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.2658945322036743\n",
      "\t\tAccuracy: 0.9263239502906799\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.2628156542778015\n",
      "\t\tAccuracy: 0.9265891909599304\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.2550933063030243\n",
      "\t\tAccuracy: 0.9271789193153381\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.2413279265165329\n",
      "\t\tAccuracy: 0.9311023354530334\n",
      "After 2 epochs:\n",
      "\tTraining Cost: 0.27299991250038147\n",
      "\tTraining Accuracy: 0.9212999939918518\n",
      "\tValidation Cost: 0.25881272554397583\n",
      "\tValidation Accuracy: 0.9247000217437744\n",
      "\tStep 100:\n",
      "\t\tCost: 0.2577403783798218\n",
      "\t\tAccuracy: 0.9262683391571045\n",
      "\tStep 200:\n",
      "\t\tCost: 0.25342363119125366\n",
      "\t\tAccuracy: 0.927484393119812\n",
      "\tStep 300:\n",
      "\t\tCost: 0.2510024607181549\n",
      "\t\tAccuracy: 0.9283241033554077\n",
      "\tStep 400:\n",
      "\t\tCost: 0.247775137424469\n",
      "\t\tAccuracy: 0.9299795627593994\n",
      "\tStep 500:\n",
      "\t\tCost: 0.24462471902370453\n",
      "\t\tAccuracy: 0.9312118291854858\n",
      "\tStep 600:\n",
      "\t\tCost: 0.24123908579349518\n",
      "\t\tAccuracy: 0.9316943287849426\n",
      "\tStep 700:\n",
      "\t\tCost: 0.23566365242004395\n",
      "\t\tAccuracy: 0.9335553050041199\n",
      "\tStep 800:\n",
      "\t\tCost: 0.232427716255188\n",
      "\t\tAccuracy: 0.9344302415847778\n",
      "\tStep 900:\n",
      "\t\tCost: 0.22953727841377258\n",
      "\t\tAccuracy: 0.9355689287185669\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.22486072778701782\n",
      "\t\tAccuracy: 0.9370563626289368\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.21812783181667328\n",
      "\t\tAccuracy: 0.9393877983093262\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.21032819151878357\n",
      "\t\tAccuracy: 0.941884458065033\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.2045823186635971\n",
      "\t\tAccuracy: 0.9434297680854797\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.19820433855056763\n",
      "\t\tAccuracy: 0.9451452493667603\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.18910789489746094\n",
      "\t\tAccuracy: 0.9448819160461426\n",
      "After 3 epochs:\n",
      "\tTraining Cost: 0.23453445732593536\n",
      "\tTraining Accuracy: 0.9333599805831909\n",
      "\tValidation Cost: 0.22278794646263123\n",
      "\tValidation Accuracy: 0.9381999969482422\n",
      "\tStep 100:\n",
      "\t\tCost: 0.22456969320774078\n",
      "\t\tAccuracy: 0.9361120462417603\n",
      "\tStep 200:\n",
      "\t\tCost: 0.22402282059192657\n",
      "\t\tAccuracy: 0.9365832209587097\n",
      "\tStep 300:\n",
      "\t\tCost: 0.221544086933136\n",
      "\t\tAccuracy: 0.9368816614151001\n",
      "\tStep 400:\n",
      "\t\tCost: 0.21990138292312622\n",
      "\t\tAccuracy: 0.9373120069503784\n",
      "\tStep 500:\n",
      "\t\tCost: 0.21712905168533325\n",
      "\t\tAccuracy: 0.937940776348114\n",
      "\tStep 600:\n",
      "\t\tCost: 0.2165374606847763\n",
      "\t\tAccuracy: 0.9385703206062317\n",
      "\tStep 700:\n",
      "\t\tCost: 0.2150600403547287\n",
      "\t\tAccuracy: 0.9391647577285767\n",
      "\tStep 800:\n",
      "\t\tCost: 0.2143680602312088\n",
      "\t\tAccuracy: 0.9393008947372437\n",
      "\tStep 900:\n",
      "\t\tCost: 0.21381668746471405\n",
      "\t\tAccuracy: 0.9399491548538208\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.214025616645813\n",
      "\t\tAccuracy: 0.9398846626281738\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.2128019630908966\n",
      "\t\tAccuracy: 0.9399946331977844\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.21054112911224365\n",
      "\t\tAccuracy: 0.94205641746521\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.2077694833278656\n",
      "\t\tAccuracy: 0.9433112144470215\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.19778239727020264\n",
      "\t\tAccuracy: 0.9472476840019226\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.20107179880142212\n",
      "\t\tAccuracy: 0.9458661675453186\n",
      "After 4 epochs:\n",
      "\tTraining Cost: 0.21234877407550812\n",
      "\tTraining Accuracy: 0.938979983329773\n",
      "\tValidation Cost: 0.20763859152793884\n",
      "\tValidation Accuracy: 0.9420999884605408\n",
      "\tStep 100:\n",
      "\t\tCost: 0.20081037282943726\n",
      "\t\tAccuracy: 0.9435855746269226\n",
      "\tStep 200:\n",
      "\t\tCost: 0.1984042525291443\n",
      "\t\tAccuracy: 0.9441235661506653\n",
      "\tStep 300:\n",
      "\t\tCost: 0.19496646523475647\n",
      "\t\tAccuracy: 0.945612370967865\n",
      "\tStep 400:\n",
      "\t\tCost: 0.19494660198688507\n",
      "\t\tAccuracy: 0.9454501271247864\n",
      "\tStep 500:\n",
      "\t\tCost: 0.19274595379829407\n",
      "\t\tAccuracy: 0.9459332227706909\n",
      "\tStep 600:\n",
      "\t\tCost: 0.1904122531414032\n",
      "\t\tAccuracy: 0.946451723575592\n",
      "\tStep 700:\n",
      "\t\tCost: 0.18703748285770416\n",
      "\t\tAccuracy: 0.9475607872009277\n",
      "\tStep 800:\n",
      "\t\tCost: 0.1838870495557785\n",
      "\t\tAccuracy: 0.9481827020645142\n",
      "\tStep 900:\n",
      "\t\tCost: 0.18073716759681702\n",
      "\t\tAccuracy: 0.9485682249069214\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.18067991733551025\n",
      "\t\tAccuracy: 0.948591411113739\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.1764247864484787\n",
      "\t\tAccuracy: 0.9499056339263916\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.1714886873960495\n",
      "\t\tAccuracy: 0.9508253335952759\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.1618955135345459\n",
      "\t\tAccuracy: 0.9538662433624268\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.15923763811588287\n",
      "\t\tAccuracy: 0.9525994062423706\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.15234048664569855\n",
      "\t\tAccuracy: 0.9611220359802246\n",
      "After 5 epochs:\n",
      "\tTraining Cost: 0.19286982715129852\n",
      "\tTraining Accuracy: 0.9452400207519531\n",
      "\tValidation Cost: 0.18959003686904907\n",
      "\tValidation Accuracy: 0.9480999708175659\n",
      "\tStep 100:\n",
      "\t\tCost: 0.18107518553733826\n",
      "\t\tAccuracy: 0.9491800665855408\n",
      "\tStep 200:\n",
      "\t\tCost: 0.17859618365764618\n",
      "\t\tAccuracy: 0.9495782852172852\n",
      "\tStep 300:\n",
      "\t\tCost: 0.1761460155248642\n",
      "\t\tAccuracy: 0.9500890374183655\n",
      "\tStep 400:\n",
      "\t\tCost: 0.17468665540218353\n",
      "\t\tAccuracy: 0.9503653049468994\n",
      "\tStep 500:\n",
      "\t\tCost: 0.17442986369132996\n",
      "\t\tAccuracy: 0.95039963722229\n",
      "\tStep 600:\n",
      "\t\tCost: 0.17316143214702606\n",
      "\t\tAccuracy: 0.9508951902389526\n",
      "\tStep 700:\n",
      "\t\tCost: 0.16846685111522675\n",
      "\t\tAccuracy: 0.9518312215805054\n",
      "\tStep 800:\n",
      "\t\tCost: 0.16764338314533234\n",
      "\t\tAccuracy: 0.9523166418075562\n",
      "\tStep 900:\n",
      "\t\tCost: 0.16588695347309113\n",
      "\t\tAccuracy: 0.9533251523971558\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.16240718960762024\n",
      "\t\tAccuracy: 0.9550244212150574\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.15677796304225922\n",
      "\t\tAccuracy: 0.9573894143104553\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.15575876832008362\n",
      "\t\tAccuracy: 0.95778888463974\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.14794456958770752\n",
      "\t\tAccuracy: 0.9603890180587769\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.1474139541387558\n",
      "\t\tAccuracy: 0.9602446556091309\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.13951943814754486\n",
      "\t\tAccuracy: 0.961614191532135\n",
      "After 6 epochs:\n",
      "\tTraining Cost: 0.16963785886764526\n",
      "\tTraining Accuracy: 0.9526000022888184\n",
      "\tValidation Cost: 0.17108319699764252\n",
      "\tValidation Accuracy: 0.9538999795913696\n",
      "\tStep 100:\n",
      "\t\tCost: 0.1657113879919052\n",
      "\t\tAccuracy: 0.953301191329956\n",
      "\tStep 200:\n",
      "\t\tCost: 0.16322718560695648\n",
      "\t\tAccuracy: 0.9541162252426147\n",
      "\tStep 300:\n",
      "\t\tCost: 0.16181576251983643\n",
      "\t\tAccuracy: 0.9545162320137024\n",
      "\tStep 400:\n",
      "\t\tCost: 0.15967680513858795\n",
      "\t\tAccuracy: 0.9551461338996887\n",
      "\tStep 500:\n",
      "\t\tCost: 0.15821847319602966\n",
      "\t\tAccuracy: 0.9556887745857239\n",
      "\tStep 600:\n",
      "\t\tCost: 0.15786811709403992\n",
      "\t\tAccuracy: 0.9557278156280518\n",
      "\tStep 700:\n",
      "\t\tCost: 0.1563117802143097\n",
      "\t\tAccuracy: 0.9558120965957642\n",
      "\tStep 800:\n",
      "\t\tCost: 0.15642666816711426\n",
      "\t\tAccuracy: 0.9556319713592529\n",
      "\tStep 900:\n",
      "\t\tCost: 0.15700197219848633\n",
      "\t\tAccuracy: 0.9558213949203491\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.15465505421161652\n",
      "\t\tAccuracy: 0.9565771818161011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStep 1100:\n",
      "\t\tCost: 0.15030783414840698\n",
      "\t\tAccuracy: 0.957591712474823\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.1483376920223236\n",
      "\t\tAccuracy: 0.9577028751373291\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.1429135948419571\n",
      "\t\tAccuracy: 0.9605075716972351\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.1362231820821762\n",
      "\t\tAccuracy: 0.9644495248794556\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.13032200932502747\n",
      "\t\tAccuracy: 0.9635826945304871\n",
      "After 7 epochs:\n",
      "\tTraining Cost: 0.15549229085445404\n",
      "\tTraining Accuracy: 0.956279993057251\n",
      "\tValidation Cost: 0.15961115062236786\n",
      "\tValidation Accuracy: 0.9559999704360962\n",
      "\tStep 100:\n",
      "\t\tCost: 0.15175625681877136\n",
      "\t\tAccuracy: 0.9568670988082886\n",
      "\tStep 200:\n",
      "\t\tCost: 0.1508820503950119\n",
      "\t\tAccuracy: 0.9573707580566406\n",
      "\tStep 300:\n",
      "\t\tCost: 0.1486654281616211\n",
      "\t\tAccuracy: 0.9583003520965576\n",
      "\tStep 400:\n",
      "\t\tCost: 0.1474107950925827\n",
      "\t\tAccuracy: 0.9585303068161011\n",
      "\tStep 500:\n",
      "\t\tCost: 0.14803391695022583\n",
      "\t\tAccuracy: 0.9587153196334839\n",
      "\tStep 600:\n",
      "\t\tCost: 0.1466633379459381\n",
      "\t\tAccuracy: 0.9593279957771301\n",
      "\tStep 700:\n",
      "\t\tCost: 0.14747026562690735\n",
      "\t\tAccuracy: 0.9588882327079773\n",
      "\tStep 800:\n",
      "\t\tCost: 0.14560571312904358\n",
      "\t\tAccuracy: 0.9598067998886108\n",
      "\tStep 900:\n",
      "\t\tCost: 0.14441192150115967\n",
      "\t\tAccuracy: 0.959447979927063\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.1423579603433609\n",
      "\t\tAccuracy: 0.9598491787910461\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.14055998623371124\n",
      "\t\tAccuracy: 0.9592097997665405\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.13630157709121704\n",
      "\t\tAccuracy: 0.9607977867126465\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.1300051361322403\n",
      "\t\tAccuracy: 0.962879478931427\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.12671224772930145\n",
      "\t\tAccuracy: 0.9636850357055664\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.12056832760572433\n",
      "\t\tAccuracy: 0.9680117964744568\n",
      "After 8 epochs:\n",
      "\tTraining Cost: 0.14598199725151062\n",
      "\tTraining Accuracy: 0.9587000012397766\n",
      "\tValidation Cost: 0.15330742299556732\n",
      "\tValidation Accuracy: 0.95660001039505\n",
      "\tStep 100:\n",
      "\t\tCost: 0.13894064724445343\n",
      "\t\tAccuracy: 0.9610949754714966\n",
      "\tStep 200:\n",
      "\t\tCost: 0.1375783383846283\n",
      "\t\tAccuracy: 0.9611982107162476\n",
      "\tStep 300:\n",
      "\t\tCost: 0.13747267425060272\n",
      "\t\tAccuracy: 0.961317777633667\n",
      "\tStep 400:\n",
      "\t\tCost: 0.13704711198806763\n",
      "\t\tAccuracy: 0.9615921974182129\n",
      "\tStep 500:\n",
      "\t\tCost: 0.13676059246063232\n",
      "\t\tAccuracy: 0.9618006348609924\n",
      "\tStep 600:\n",
      "\t\tCost: 0.1366051435470581\n",
      "\t\tAccuracy: 0.9619551301002502\n",
      "\tStep 700:\n",
      "\t\tCost: 0.13489824533462524\n",
      "\t\tAccuracy: 0.9626157879829407\n",
      "\tStep 800:\n",
      "\t\tCost: 0.13404971361160278\n",
      "\t\tAccuracy: 0.9630811810493469\n",
      "\tStep 900:\n",
      "\t\tCost: 0.13211268186569214\n",
      "\t\tAccuracy: 0.9642520546913147\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.12947393953800201\n",
      "\t\tAccuracy: 0.9652284979820251\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.1262170523405075\n",
      "\t\tAccuracy: 0.9665588140487671\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.12429393082857132\n",
      "\t\tAccuracy: 0.9687070250511169\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.1187763661146164\n",
      "\t\tAccuracy: 0.9696394801139832\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.1158522516489029\n",
      "\t\tAccuracy: 0.9709480404853821\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.11273814737796783\n",
      "\t\tAccuracy: 0.9709645509719849\n",
      "After 9 epochs:\n",
      "\tTraining Cost: 0.13541679084300995\n",
      "\tTraining Accuracy: 0.9617199897766113\n",
      "\tValidation Cost: 0.14386290311813354\n",
      "\tValidation Accuracy: 0.9606000185012817\n",
      "\tStep 100:\n",
      "\t\tCost: 0.12929673492908478\n",
      "\t\tAccuracy: 0.9638708829879761\n",
      "\tStep 200:\n",
      "\t\tCost: 0.12810368835926056\n",
      "\t\tAccuracy: 0.9639943242073059\n",
      "\tStep 300:\n",
      "\t\tCost: 0.12765203416347504\n",
      "\t\tAccuracy: 0.9639889001846313\n",
      "\tStep 400:\n",
      "\t\tCost: 0.12655271589756012\n",
      "\t\tAccuracy: 0.964385449886322\n",
      "\tStep 500:\n",
      "\t\tCost: 0.12606710195541382\n",
      "\t\tAccuracy: 0.9651210904121399\n",
      "\tStep 600:\n",
      "\t\tCost: 0.1254475712776184\n",
      "\t\tAccuracy: 0.9653282165527344\n",
      "\tStep 700:\n",
      "\t\tCost: 0.12384619563817978\n",
      "\t\tAccuracy: 0.9656919240951538\n",
      "\tStep 800:\n",
      "\t\tCost: 0.12274226546287537\n",
      "\t\tAccuracy: 0.9666011929512024\n",
      "\tStep 900:\n",
      "\t\tCost: 0.12275844067335129\n",
      "\t\tAccuracy: 0.9667953848838806\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.12266466021537781\n",
      "\t\tAccuracy: 0.9665594696998596\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.12286115437746048\n",
      "\t\tAccuracy: 0.9673678278923035\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.12012280523777008\n",
      "\t\tAccuracy: 0.9680192470550537\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.11780514568090439\n",
      "\t\tAccuracy: 0.9679791331291199\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.11050921678543091\n",
      "\t\tAccuracy: 0.9719036817550659\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.10484787821769714\n",
      "\t\tAccuracy: 0.9729330539703369\n",
      "After 10 epochs:\n",
      "\tTraining Cost: 0.12451339513063431\n",
      "\tTraining Accuracy: 0.965179979801178\n",
      "\tValidation Cost: 0.1383022964000702\n",
      "\tValidation Accuracy: 0.9613999724388123\n",
      "\tStep 100:\n",
      "\t\tCost: 0.11918660253286362\n",
      "\t\tAccuracy: 0.9670097231864929\n",
      "\tStep 200:\n",
      "\t\tCost: 0.11726955324411392\n",
      "\t\tAccuracy: 0.9677759408950806\n",
      "\tStep 300:\n",
      "\t\tCost: 0.11651494354009628\n",
      "\t\tAccuracy: 0.9680945873260498\n",
      "\tStep 400:\n",
      "\t\tCost: 0.11610491573810577\n",
      "\t\tAccuracy: 0.9680919647216797\n",
      "\tStep 500:\n",
      "\t\tCost: 0.11665268987417221\n",
      "\t\tAccuracy: 0.9678537845611572\n",
      "\tStep 600:\n",
      "\t\tCost: 0.11689505726099014\n",
      "\t\tAccuracy: 0.9678256511688232\n",
      "\tStep 700:\n",
      "\t\tCost: 0.11538343131542206\n",
      "\t\tAccuracy: 0.9683338403701782\n",
      "\tStep 800:\n",
      "\t\tCost: 0.11423106491565704\n",
      "\t\tAccuracy: 0.968934178352356\n",
      "\tStep 900:\n",
      "\t\tCost: 0.11185336112976074\n",
      "\t\tAccuracy: 0.9697626233100891\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.11064361035823822\n",
      "\t\tAccuracy: 0.970108687877655\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.11058235168457031\n",
      "\t\tAccuracy: 0.970671534538269\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.10967586189508438\n",
      "\t\tAccuracy: 0.971028208732605\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.10702190548181534\n",
      "\t\tAccuracy: 0.9727229475975037\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.10278318077325821\n",
      "\t\tAccuracy: 0.9745795130729675\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.10903436690568924\n",
      "\t\tAccuracy: 0.9739173054695129\n",
      "Model saved in path: ./model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def one_hot(Y, classes):\n",
    "    \"\"\"convert an array to a one-hot matrix\"\"\"\n",
    "    oh = np.zeros((Y.shape[0], classes))\n",
    "    oh[np.arange(Y.shape[0]), Y] = 1\n",
    "    return oh\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lib= np.load('../data/MNIST.npz')\n",
    "    X_train_3D = lib['X_train']\n",
    "    Y_train = lib['Y_train']\n",
    "    X_train = X_train_3D.reshape((X_train_3D.shape[0], -1))\n",
    "    Y_train_oh = one_hot(Y_train, 10)\n",
    "    X_valid_3D = lib['X_valid']\n",
    "    Y_valid = lib['Y_valid']\n",
    "    X_valid = X_valid_3D.reshape((X_valid_3D.shape[0], -1))\n",
    "    Y_valid_oh = one_hot(Y_valid, 10)\n",
    "\n",
    "    layer_sizes = [256, 256, 10]\n",
    "    activations = [tf.nn.tanh, tf.nn.tanh, None]\n",
    "    alpha = 0.01\n",
    "    iterations = 5000\n",
    "\n",
    "    np.random.seed(0)\n",
    "    save_path = train_mini_batch(X_train, Y_train_oh, X_valid, Y_valid_oh,\n",
    "                                 epochs=10, load_path='./graph.ckpt',\n",
    "                                 save_path='./model.ckpt')\n",
    "    print('Model saved in path: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98556ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
