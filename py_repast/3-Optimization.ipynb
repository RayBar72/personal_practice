{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c454d0cc",
   "metadata": {},
   "source": [
    "# Task 0 - Normalization Constants\n",
    "Write the function def normalization_constants(X): that calculates the normalization (standardization) constants of a matrix:\n",
    "- X is the numpy.ndarray of shape (m, nx) to normalize\n",
    "    - m is the number of data points\n",
    "    - nx is the number of features\n",
    "- Returns: the mean and standard deviation of each feature, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b332c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalization_constants(X):\n",
    "    ave = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return ave, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f954ee6",
   "metadata": {},
   "source": [
    "### Comentarios\n",
    "- Se utiliza con respecto al eje x, es decir, promedia renglón a renglón\n",
    "- Se obtiene el promedio de cada valor de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "838f3bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11961603  2.08201297 -3.59232261]\n",
      "[2.01576449 1.034667   9.52002619]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1599cf9",
   "metadata": {},
   "source": [
    "# Task 1 - Normalize\n",
    "Write the function def normalize(X, m, s): that normalizes (standardizes) a matrix:\n",
    "- X is the numpy.ndarray of shape (d, nx) to normalize\n",
    "    - d is the number of data points\n",
    "    - nx is the number of features\n",
    "- m is a numpy.ndarray of shape (nx,) that contains the mean of all features of X\n",
    "- s is a numpy.ndarray of shape (nx,) that contains the standard deviation of all features of X\n",
    "- Returns: The normalized X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9df43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(X, m, s):\n",
    "    x = np.subtract(X, m)\n",
    "    ret = np.divide(x, s)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de1805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.52810469   3.8831507   -6.69181838]\n",
      " [  0.80031442   0.65224094  -5.39379178]\n",
      " [  1.95747597   0.729515     7.99659596]\n",
      " [  4.4817864    2.96939671   3.55263731]\n",
      " [  3.73511598   0.82687659   3.40131526]\n",
      " [ -1.95455576   3.94362119 -19.16956044]\n",
      " [  1.90017684   1.58638102  -3.24326124]\n",
      " [ -0.30271442   1.25254519 -10.38030909]\n",
      " [ -0.2064377    3.92294203  -0.20075401]\n",
      " [  0.821197     3.48051479  -3.9815039 ]]\n",
      "[[ 1.69091612  1.74078977 -0.32557639]\n",
      " [ 0.33768746 -1.38186686 -0.18922943]\n",
      " [ 0.91174338 -1.3071819   1.21732003]\n",
      " [ 2.16402779  0.85765153  0.75051893]\n",
      " [ 1.79361228 -1.21308245  0.73462381]\n",
      " [-1.02897526  1.79923417 -1.63625998]\n",
      " [ 0.88331787 -0.47902557  0.03666601]\n",
      " [-0.20951378 -0.80167608 -0.71302183]\n",
      " [-0.1617519   1.77924787  0.35625623]\n",
      " [ 0.34804709  1.35164437 -0.04088028]]\n",
      "[ 2.44249065e-17 -4.99600361e-16  1.46549439e-16]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(X[:10])\n",
    "    X = normalize(X, m, s)\n",
    "    print(X[:10])\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b87d4",
   "metadata": {},
   "source": [
    "# Task 2 - Shuffle Data\n",
    "Write the function def shuffle_data(X, Y): that shuffles the data points in two matrices the same way:\n",
    "- X is the first numpy.ndarray of shape (m, nx) to shuffle\n",
    "    - m is the number of data points\n",
    "    - nx is the number of features in X\n",
    "- Y is the second numpy.ndarray of shape (m, ny) to shuffle\n",
    "    - m is the same number of data points as in X\n",
    "    - ny is the number of features in Y\n",
    "- Returns: the shuffled X and Y matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14260cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def shuffle_data(X, Y):\n",
    "    m = X.shape[0]\n",
    "    shuf_vect = np.random.permutation(m)\n",
    "    print(shuf_vect)\n",
    "    x = X[shuf_vect]\n",
    "    y = Y[shuf_vect]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991ec00",
   "metadata": {},
   "source": [
    "### Comentarios\n",
    "- Se genera un vector para hacer el \"barajeo\" porque deben de quedar en forma correspondiente x, y\n",
    "- En este ejemplo se genera el vector [2 0 1 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76638ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3 4]\n",
      "[[ 5  6]\n",
      " [ 1  2]\n",
      " [ 3  4]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "[[15 16]\n",
      " [11 12]\n",
      " [13 14]\n",
      " [17 18]\n",
      " [19 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = np.array([[1, 2],\n",
    "                [3, 4],\n",
    "                [5, 6],\n",
    "                [7, 8], \n",
    "                [9, 10]])\n",
    "    Y = np.array([[11, 12],\n",
    "                [13, 14],\n",
    "                [15, 16],\n",
    "                [17, 18],\n",
    "                [19, 20]])\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X_shuffled, Y_shuffled = shuffle_data(X, Y)\n",
    "\n",
    "    print(X_shuffled)\n",
    "    print(Y_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765d24",
   "metadata": {},
   "source": [
    "# Task 3 - Mini-Batch\n",
    "Write the function def train_mini_batch(X_train, Y_train, X_valid, Y_valid, batch_size=32, epochs=5, load_path=\"/tmp/model.ckpt\", save_path=\"/tmp/model.ckpt\"): that trains a loaded neural network model using mini-batch gradient descent:\n",
    "- X_train is a numpy.ndarray of shape (m, 784) containing the training data\n",
    "- m is the number of data points\n",
    "- 784 is the number of input features\n",
    "- Y_train is a one-hot numpy.ndarray of shape (m, 10) containing the training labels\n",
    "- 10 is the number of classes the model should classify\n",
    "- X_valid is a numpy.ndarray of shape (m, 784) containing the validation data\n",
    "- Y_valid is a one-hot numpy.ndarray of shape (m, 10) containing the validation labels\n",
    "- batch_size is the number of data points in a batch\n",
    "- epochs is the number of times the training should pass through the whole dataset\n",
    "- load_path is the path from which to load the model\n",
    "- save_path is the path to where the model should be saved after training\n",
    "- Returns: the path where the model was saved\n",
    "- Your training function should allow for a smaller final batch (a.k.a. use the entire training set)\n",
    "1) import meta graph and restore session\n",
    "2) Get the following tensors and ops from the collection restored\n",
    "    - x is a placeholder for the input data\n",
    "    - y is a placeholder for the labels\n",
    "    - accuracy is an op to calculate the accuracy of the model\n",
    "    - loss is an op to calculate the cost of the model\n",
    "    - train_op is an op to perform one pass of gradient descent on the model\n",
    "3) loop over epochs:\n",
    "    - shuffle data\n",
    "    - loop over the batches:\n",
    "        - get X_batch and Y_batch from data\n",
    "        - train your model\n",
    "4) Save session\n",
    "- You should use shuffle_data = __import__('2-shuffle_data').shuffle_data\n",
    "- Before the first epoch and after every subsequent epoch, the following should be printed:\n",
    "    - After {epoch} epochs: where {epoch} is the current epoch\n",
    "    - \\tTraining Cost: {train_cost} where {train_cost} is the cost of the model on the entire training set\n",
    "    - \\tTraining Accuracy: {train_accuracy} where {train_accuracy} is the accuracy of the model on the entire training set\n",
    "    - \\tValidation Cost: {valid_cost} where {valid_cost} is the cost of the model on the entire validation set\n",
    "    - \\tValidation Accuracy: {valid_accuracy} where {valid_accuracy} is the accuracy of the model on the entire validation set\n",
    "- After every 100 steps gradient descent within an epoch, the following should be printed:\n",
    "    - \\tStep {step_number}: where {step_number} is the number of times gradient descent has been run in the current epoch\n",
    "    - \\t\\tCost: {step_cost} where {step_cost} is the cost of the model on the current mini-batch\n",
    "    - \\t\\tAccuracy: {step_accuracy} where {step_accuracy} is the accuracy of the model on the current mini-batch\n",
    "    - Advice: the function range can help you to handle this loop inside your dataset by using batch_size as step value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626a26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
