{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c454d0cc",
   "metadata": {},
   "source": [
    "# Task 0 - Normalization Constants\n",
    "Write the function def normalization_constants(X): that calculates the normalization (standardization) constants of a matrix:\n",
    "- X is the numpy.ndarray of shape (m, nx) to normalize\n",
    "    - m is the number of data points\n",
    "    - nx is the number of features\n",
    "- Returns: the mean and standard deviation of each feature, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b332c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalization_constants(X):\n",
    "    ave = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return ave, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f954ee6",
   "metadata": {},
   "source": [
    "### Comentarios\n",
    "- Se utiliza con respecto al eje x, es decir, promedia renglón a renglón\n",
    "- Se obtiene el promedio de cada valor de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838f3bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11961603  2.08201297 -3.59232261]\n",
      "[2.01576449 1.034667   9.52002619]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1599cf9",
   "metadata": {},
   "source": [
    "# Task 1 - Normalize\n",
    "Write the function def normalize(X, m, s): that normalizes (standardizes) a matrix:\n",
    "- X is the numpy.ndarray of shape (d, nx) to normalize\n",
    "    - d is the number of data points\n",
    "    - nx is the number of features\n",
    "- m is a numpy.ndarray of shape (nx,) that contains the mean of all features of X\n",
    "- s is a numpy.ndarray of shape (nx,) that contains the standard deviation of all features of X\n",
    "- Returns: The normalized X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9df43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(X, m, s):\n",
    "    x = np.subtract(X, m)\n",
    "    ret = np.divide(x, s)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de1805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.52810469   3.8831507   -6.69181838]\n",
      " [  0.80031442   0.65224094  -5.39379178]\n",
      " [  1.95747597   0.729515     7.99659596]\n",
      " [  4.4817864    2.96939671   3.55263731]\n",
      " [  3.73511598   0.82687659   3.40131526]\n",
      " [ -1.95455576   3.94362119 -19.16956044]\n",
      " [  1.90017684   1.58638102  -3.24326124]\n",
      " [ -0.30271442   1.25254519 -10.38030909]\n",
      " [ -0.2064377    3.92294203  -0.20075401]\n",
      " [  0.821197     3.48051479  -3.9815039 ]]\n",
      "[[ 1.69091612  1.74078977 -0.32557639]\n",
      " [ 0.33768746 -1.38186686 -0.18922943]\n",
      " [ 0.91174338 -1.3071819   1.21732003]\n",
      " [ 2.16402779  0.85765153  0.75051893]\n",
      " [ 1.79361228 -1.21308245  0.73462381]\n",
      " [-1.02897526  1.79923417 -1.63625998]\n",
      " [ 0.88331787 -0.47902557  0.03666601]\n",
      " [-0.20951378 -0.80167608 -0.71302183]\n",
      " [-0.1617519   1.77924787  0.35625623]\n",
      " [ 0.34804709  1.35164437 -0.04088028]]\n",
      "[ 2.44249065e-17 -4.99600361e-16  1.46549439e-16]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(0, 2, size=(100, 1))\n",
    "    b = np.random.normal(2, 1, size=(100, 1))\n",
    "    c = np.random.normal(-3, 10, size=(100, 1))\n",
    "    X = np.concatenate((a, b, c), axis=1)\n",
    "    m, s = normalization_constants(X)\n",
    "    print(X[:10])\n",
    "    X = normalize(X, m, s)\n",
    "    print(X[:10])\n",
    "    m, s = normalization_constants(X)\n",
    "    print(m)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b87d4",
   "metadata": {},
   "source": [
    "# Task 2 - Shuffle Data\n",
    "Write the function def shuffle_data(X, Y): that shuffles the data points in two matrices the same way:\n",
    "- X is the first numpy.ndarray of shape (m, nx) to shuffle\n",
    "    - m is the number of data points\n",
    "    - nx is the number of features in X\n",
    "- Y is the second numpy.ndarray of shape (m, ny) to shuffle\n",
    "    - m is the same number of data points as in X\n",
    "    - ny is the number of features in Y\n",
    "- Returns: the shuffled X and Y matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14260cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def shuffle_data(X, Y):\n",
    "    m = X.shape[0]\n",
    "    shuf_vect = np.random.permutation(m)\n",
    "    print(shuf_vect)\n",
    "    x = X[shuf_vect]\n",
    "    y = Y[shuf_vect]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991ec00",
   "metadata": {},
   "source": [
    "### Comentarios\n",
    "- Se genera un vector para hacer el \"barajeo\" porque deben de quedar en forma correspondiente x, y\n",
    "- En este ejemplo se genera el vector [2 0 1 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76638ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3 4]\n",
      "[[ 5  6]\n",
      " [ 1  2]\n",
      " [ 3  4]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "[[15 16]\n",
      " [11 12]\n",
      " [13 14]\n",
      " [17 18]\n",
      " [19 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = np.array([[1, 2],\n",
    "                [3, 4],\n",
    "                [5, 6],\n",
    "                [7, 8], \n",
    "                [9, 10]])\n",
    "    Y = np.array([[11, 12],\n",
    "                [13, 14],\n",
    "                [15, 16],\n",
    "                [17, 18],\n",
    "                [19, 20]])\n",
    "\n",
    "    np.random.seed(0)\n",
    "    X_shuffled, Y_shuffled = shuffle_data(X, Y)\n",
    "\n",
    "    print(X_shuffled)\n",
    "    print(Y_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765d24",
   "metadata": {},
   "source": [
    "# Task 3 - Mini-Batch\n",
    "Write the function def train_mini_batch(X_train, Y_train, X_valid, Y_valid, batch_size=32, epochs=5, load_path=\"/tmp/model.ckpt\", save_path=\"/tmp/model.ckpt\"): that trains a loaded neural network model using mini-batch gradient descent:\n",
    "- X_train is a numpy.ndarray of shape (m, 784) containing the training data\n",
    "- m is the number of data points\n",
    "- 784 is the number of input features\n",
    "- Y_train is a one-hot numpy.ndarray of shape (m, 10) containing the training labels\n",
    "- 10 is the number of classes the model should classify\n",
    "- X_valid is a numpy.ndarray of shape (m, 784) containing the validation data\n",
    "- Y_valid is a one-hot numpy.ndarray of shape (m, 10) containing the validation labels\n",
    "- batch_size is the number of data points in a batch\n",
    "- epochs is the number of times the training should pass through the whole dataset\n",
    "- load_path is the path from which to load the model\n",
    "- save_path is the path to where the model should be saved after training\n",
    "- Returns: the path where the model was saved\n",
    "- Your training function should allow for a smaller final batch (a.k.a. use the entire training set)\n",
    "1. import meta graph and restore session\n",
    "2. Get the following tensors and ops from the collection restored\n",
    "    - x is a placeholder for the input data\n",
    "    - y is a placeholder for the labels\n",
    "    - accuracy is an op to calculate the accuracy of the model\n",
    "    - loss is an op to calculate the cost of the model\n",
    "    - train_op is an op to perform one pass of gradient descent on the model\n",
    "3. loop over epochs:\n",
    "    - shuffle data\n",
    "    - loop over the batches:\n",
    "        - get X_batch and Y_batch from data\n",
    "        - train your model\n",
    "4. Save session\n",
    "- You should use shuffle_data = __import__('2-shuffle_data').shuffle_data\n",
    "- Before the first epoch and after every subsequent epoch, the following should be printed:\n",
    "    - After {epoch} epochs: where {epoch} is the current epoch\n",
    "    - \\tTraining Cost: {train_cost} where {train_cost} is the cost of the model on the entire training set\n",
    "    - \\tTraining Accuracy: {train_accuracy} where {train_accuracy} is the accuracy of the model on the entire training set\n",
    "    - \\tValidation Cost: {valid_cost} where {valid_cost} is the cost of the model on the entire validation set\n",
    "    - \\tValidation Accuracy: {valid_accuracy} where {valid_accuracy} is the accuracy of the model on the entire validation set\n",
    "- After every 100 steps gradient descent within an epoch, the following should be printed:\n",
    "    - \\tStep {step_number}: where {step_number} is the number of times gradient descent has been run in the current epoch\n",
    "    - \\t\\tCost: {step_cost} where {step_cost} is the cost of the model on the current mini-batch\n",
    "    - \\t\\tAccuracy: {step_accuracy} where {step_accuracy} is the accuracy of the model on the current mini-batch\n",
    "    - Advice: the function range can help you to handle this loop inside your dataset by using batch_size as step value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8626a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "def train_mini_batch(X_train, Y_train, X_valid, Y_valid, batch_size=32, epochs=5,\n",
    "                     load_path=\"/tmp/model.ckpt\", save_path=\"/tmp/model.ckpt\"): \n",
    "#     Importing the graph\n",
    "    with tf.Session() as session:\n",
    "        saved = tf.train.import_meta_graph('{}.meta'.format(load_path))\n",
    "        saved.restore(session, load_path)\n",
    "        x = tf.get_collection('x')[0]\n",
    "        y = tf.get_collection('y')[0]\n",
    "        accuracy = tf.get_collection('accuracy')[0]\n",
    "        loss = tf.get_collection('loss')[0]\n",
    "        train_op = tf.get_collection('train_op')[0]\n",
    "#         Establishing number of batches\n",
    "        m = X_train.shape[0]\n",
    "        if m % batch_size == 0:\n",
    "            mini = int(m / batch_size)\n",
    "            case = 0\n",
    "        else:\n",
    "            mini = int(m / batch_size) + 1\n",
    "            case = 1\n",
    "#         Epoch loop\n",
    "        for e in range(epochs + 1):\n",
    "#             Running loss, accuracy and tran function\n",
    "            d_train = {x: X_train, y: Y_train}\n",
    "            d_valid = {x: X_valid, y: Y_valid}\n",
    "            t_cost = session.run(loss, feed_dict=d_train)\n",
    "            t_accuracy = session.run(accuracy, feed_dict=d_train)\n",
    "            t_train_op = session.run(loss, feed_dict=d_train)\n",
    "            v_cost = session.run(loss, feed_dict=d_valid)\n",
    "            v_accuracy = session.run(accuracy, feed_dict=d_valid)\n",
    "            print('After {} epochs:'.format(e))\n",
    "            print('\\tTraining Cost: {}'.format(t_cost))\n",
    "            print('\\tTraining Accuracy: {}'.format(t_accuracy))\n",
    "            print('\\tValidation Cost: {}'.format(v_cost))\n",
    "            print('\\tValidation Accuracy: {}'.format(v_accuracy))\n",
    "            if e < epochs:\n",
    "                Xsh, Ysh = shuffle_data(X_train, Y_train)\n",
    "                for i in range(mini):\n",
    "#                     Making the batch in the shuffle data\n",
    "                    a_0 = i * batch_size\n",
    "                    a_1 = (i + 1) * batch_size\n",
    "                    if case == 0 and i == mini:\n",
    "#                     Case when is the last minibatch\n",
    "                        x_m = Xsh[a_0::]\n",
    "                        y_m = Ysh[a_0::]\n",
    "                    else:\n",
    "#                     Other cases\n",
    "                        x_m = Xsh[a_0:a_1]\n",
    "                        y_m = Ysh[a_0:a_1]\n",
    "                    d_mini = {x: x_m, y: y_m}\n",
    "                    session.run(train_op, feed_dict=d_mini)\n",
    "                    if((i + 1) % 100 == 0) and (i != 0):\n",
    "                        s_cost = session.run(loss, feed_dict=d_mini)\n",
    "                        s_accuracy = session.run(accuracy, feed_dict=d_mini)\n",
    "                        print('\\tStep {}:'.format(i + 1))\n",
    "                        print('\\t\\tCost: {}'.format(s_cost))\n",
    "                        print('\\t\\tAccuracy: {}'.format(s_accuracy))\n",
    "        save_path = saved.save(session, save_path)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0215c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./graph.ckpt\n",
      "After 0 epochs:\n",
      "\tTraining Cost: 2.8232288360595703\n",
      "\tTraining Accuracy: 0.08726000040769577\n",
      "\tValidation Cost: 2.810532331466675\n",
      "[11841 19602 45519 ... 42613 43567  2732]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.9012309312820435\n",
      "\t\tAccuracy: 0.6875\n",
      "\tStep 200:\n",
      "\t\tCost: 0.632826566696167\n",
      "\t\tAccuracy: 0.8125\n",
      "\tStep 300:\n",
      "\t\tCost: 0.6980432271957397\n",
      "\t\tAccuracy: 0.8125\n",
      "\tStep 400:\n",
      "\t\tCost: 0.30890682339668274\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 500:\n",
      "\t\tCost: 0.3093193471431732\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 600:\n",
      "\t\tCost: 0.30502933263778687\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 700:\n",
      "\t\tCost: 0.5535626411437988\n",
      "\t\tAccuracy: 0.84375\n",
      "\tStep 800:\n",
      "\t\tCost: 0.3425140678882599\n",
      "\t\tAccuracy: 0.84375\n",
      "\tStep 900:\n",
      "\t\tCost: 0.35854315757751465\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.3670477569103241\n",
      "\t\tAccuracy: 0.8125\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.1867058128118515\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.18414628505706787\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.7523376941680908\n",
      "\t\tAccuracy: 0.84375\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.31485235691070557\n",
      "\t\tAccuracy: 0.8125\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.2760249078273773\n",
      "\t\tAccuracy: 0.9375\n",
      "After 1 epochs:\n",
      "\tTraining Cost: 0.3164157569408417\n",
      "\tTraining Accuracy: 0.9101600050926208\n",
      "\tValidation Cost: 0.291348934173584\n",
      "[28921 11971 15919 ... 22472 18283 36615]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.24898430705070496\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 200:\n",
      "\t\tCost: 0.13849662244319916\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 300:\n",
      "\t\tCost: 0.25501108169555664\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 400:\n",
      "\t\tCost: 0.2901785969734192\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 500:\n",
      "\t\tCost: 0.16119550168514252\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 600:\n",
      "\t\tCost: 0.06719313561916351\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 700:\n",
      "\t\tCost: 0.2965790331363678\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 800:\n",
      "\t\tCost: 0.2077041119337082\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 900:\n",
      "\t\tCost: 0.28159815073013306\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.14979934692382812\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.23720011115074158\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.10439400374889374\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.3269117474555969\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.17474406957626343\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.31896233558654785\n",
      "\t\tAccuracy: 0.875\n",
      "After 2 epochs:\n",
      "\tTraining Cost: 0.2607157528400421\n",
      "\tTraining Accuracy: 0.9253600239753723\n",
      "\tValidation Cost: 0.24720025062561035\n",
      "[36011 11643 45353 ... 22635  3695  3124]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.20514936745166779\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 200:\n",
      "\t\tCost: 0.3155081272125244\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.15549033880233765\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 400:\n",
      "\t\tCost: 0.06821946054697037\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 500:\n",
      "\t\tCost: 0.19249942898750305\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 600:\n",
      "\t\tCost: 0.2478351891040802\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 700:\n",
      "\t\tCost: 0.2374488115310669\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 800:\n",
      "\t\tCost: 0.16296833753585815\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 900:\n",
      "\t\tCost: 0.17393633723258972\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.06818355619907379\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.48284193873405457\n",
      "\t\tAccuracy: 0.8125\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.08326677978038788\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.31598255038261414\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.07795308530330658\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.22888009250164032\n",
      "\t\tAccuracy: 0.9375\n",
      "After 3 epochs:\n",
      "\tTraining Cost: 0.22760064899921417\n",
      "\tTraining Accuracy: 0.9357399940490723\n",
      "\tValidation Cost: 0.21762314438819885\n",
      "[ 8777  6584 42707 ... 18656 41141 31699]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.13111434876918793\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 200:\n",
      "\t\tCost: 0.27714237570762634\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 300:\n",
      "\t\tCost: 0.35563403367996216\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 400:\n",
      "\t\tCost: 0.21630580723285675\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 500:\n",
      "\t\tCost: 0.20642399787902832\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 600:\n",
      "\t\tCost: 0.48105835914611816\n",
      "\t\tAccuracy: 0.84375\n",
      "\tStep 700:\n",
      "\t\tCost: 0.17341731488704681\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 800:\n",
      "\t\tCost: 0.3035162687301636\n",
      "\t\tAccuracy: 0.84375\n",
      "\tStep 900:\n",
      "\t\tCost: 0.079269640147686\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.1599692702293396\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.1354656219482422\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.08835581690073013\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.21614569425582886\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.11061817407608032\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.20135566592216492\n",
      "\t\tAccuracy: 0.9375\n",
      "After 4 epochs:\n",
      "\tTraining Cost: 0.20386174321174622\n",
      "\tTraining Accuracy: 0.9422199726104736\n",
      "\tValidation Cost: 0.19994838535785675\n",
      "[31717  6298 11914 ... 19718 32979  1744]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.27469271421432495\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 200:\n",
      "\t\tCost: 0.19427166879177094\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.2524890899658203\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 400:\n",
      "\t\tCost: 0.40250498056411743\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 500:\n",
      "\t\tCost: 0.03543531894683838\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 600:\n",
      "\t\tCost: 0.06244567036628723\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 700:\n",
      "\t\tCost: 0.2825520932674408\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 800:\n",
      "\t\tCost: 0.11803165078163147\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 900:\n",
      "\t\tCost: 0.1783008873462677\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.07609303295612335\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.11033778637647629\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.16132324934005737\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.1605091243982315\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.12705457210540771\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.16342981159687042\n",
      "\t\tAccuracy: 0.9375\n",
      "After 5 epochs:\n",
      "\tTraining Cost: 0.1846235990524292\n",
      "\tTraining Accuracy: 0.9475200176239014\n",
      "\tValidation Cost: 0.18357285857200623\n",
      "[ 9673 35426  7318 ... 45097 30130 28967]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.07790108770132065\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 200:\n",
      "\t\tCost: 0.08256740868091583\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.07024182379245758\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 400:\n",
      "\t\tCost: 0.13729789853096008\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 500:\n",
      "\t\tCost: 0.055092982947826385\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 600:\n",
      "\t\tCost: 0.045438896864652634\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 700:\n",
      "\t\tCost: 0.40743955969810486\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 800:\n",
      "\t\tCost: 0.29184606671333313\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 900:\n",
      "\t\tCost: 0.38485604524612427\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.07183845341205597\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.2217615842819214\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.28817838430404663\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.102177195250988\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.08340421319007874\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.06263338774442673\n",
      "\t\tAccuracy: 0.96875\n",
      "After 6 epochs:\n",
      "\tTraining Cost: 0.16400478780269623\n",
      "\tTraining Accuracy: 0.9540799856185913\n",
      "\tValidation Cost: 0.16605588793754578\n",
      "[12886   599  5432 ... 29448 40755 20829]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.1447063684463501\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 200:\n",
      "\t\tCost: 0.08316230773925781\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.09039773046970367\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 400:\n",
      "\t\tCost: 0.21365149319171906\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 500:\n",
      "\t\tCost: 0.0572584867477417\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 600:\n",
      "\t\tCost: 0.07412075996398926\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 700:\n",
      "\t\tCost: 0.059551484882831573\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 800:\n",
      "\t\tCost: 0.065826416015625\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 900:\n",
      "\t\tCost: 0.2359517514705658\n",
      "\t\tAccuracy: 0.875\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.222974956035614\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.04838588088750839\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.15647411346435547\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.17398466169834137\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.08072973787784576\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.020014679059386253\n",
      "\t\tAccuracy: 1.0\n",
      "After 7 epochs:\n",
      "\tTraining Cost: 0.1506650149822235\n",
      "\tTraining Accuracy: 0.9574999809265137\n",
      "\tValidation Cost: 0.15625259280204773\n",
      "[ 6815 30601   148 ...  8582 28827  1747]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.09549973905086517\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 200:\n",
      "\t\tCost: 0.07694775611162186\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.08010939508676529\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 400:\n",
      "\t\tCost: 0.23830747604370117\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 500:\n",
      "\t\tCost: 0.07212645560503006\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 600:\n",
      "\t\tCost: 0.10588940978050232\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 700:\n",
      "\t\tCost: 0.12520460784435272\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 800:\n",
      "\t\tCost: 0.03333308920264244\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 900:\n",
      "\t\tCost: 0.04442461580038071\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.2641702890396118\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.05731099843978882\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.05882635340094566\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.07519375532865524\n",
      "\t\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStep 1400:\n",
      "\t\tCost: 0.06169447675347328\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.14823190867900848\n",
      "\t\tAccuracy: 0.9375\n",
      "After 8 epochs:\n",
      "\tTraining Cost: 0.13945837318897247\n",
      "\tTraining Accuracy: 0.9610999822616577\n",
      "\tValidation Cost: 0.14728352427482605\n",
      "[19652 18068  7387 ... 23883 43467 18371]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.07047389447689056\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 200:\n",
      "\t\tCost: 0.11671728640794754\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 300:\n",
      "\t\tCost: 0.2886141240596771\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 400:\n",
      "\t\tCost: 0.07110710442066193\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 500:\n",
      "\t\tCost: 0.061070073395967484\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 600:\n",
      "\t\tCost: 0.1257304698228836\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 700:\n",
      "\t\tCost: 0.06935623288154602\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 800:\n",
      "\t\tCost: 0.04435047507286072\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 900:\n",
      "\t\tCost: 0.04303248971700668\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.024514948949217796\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.1584576815366745\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.23370981216430664\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.0525774322450161\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.17371881008148193\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.16959133744239807\n",
      "\t\tAccuracy: 0.9375\n",
      "After 9 epochs:\n",
      "\tTraining Cost: 0.12963168323040009\n",
      "\tTraining Accuracy: 0.9642800092697144\n",
      "\tValidation Cost: 0.13914339244365692\n",
      "[19285 13217  7753 ... 23305 16153 33231]\n",
      "\tStep 100:\n",
      "\t\tCost: 0.10656598210334778\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 200:\n",
      "\t\tCost: 0.09849666059017181\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 300:\n",
      "\t\tCost: 0.10603410005569458\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 400:\n",
      "\t\tCost: 0.21131062507629395\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 500:\n",
      "\t\tCost: 0.1606646478176117\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 600:\n",
      "\t\tCost: 0.03922262415289879\n",
      "\t\tAccuracy: 1.0\n",
      "\tStep 700:\n",
      "\t\tCost: 0.07872801274061203\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 800:\n",
      "\t\tCost: 0.1709361970424652\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 900:\n",
      "\t\tCost: 0.222450852394104\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 1000:\n",
      "\t\tCost: 0.12781260907649994\n",
      "\t\tAccuracy: 0.9375\n",
      "\tStep 1100:\n",
      "\t\tCost: 0.14031030237674713\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1200:\n",
      "\t\tCost: 0.26136285066604614\n",
      "\t\tAccuracy: 0.90625\n",
      "\tStep 1300:\n",
      "\t\tCost: 0.08150098472833633\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1400:\n",
      "\t\tCost: 0.1133868619799614\n",
      "\t\tAccuracy: 0.96875\n",
      "\tStep 1500:\n",
      "\t\tCost: 0.09147094190120697\n",
      "\t\tAccuracy: 0.96875\n",
      "After 10 epochs:\n",
      "\tTraining Cost: 0.12012936174869537\n",
      "\tTraining Accuracy: 0.9669600129127502\n",
      "\tValidation Cost: 0.13320674002170563\n",
      "Model saved in path: ./model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "def one_hot(Y, classes):\n",
    "    \"\"\"convert an array to a one-hot matrix\"\"\"\n",
    "    oh = np.zeros((Y.shape[0], classes))\n",
    "    oh[np.arange(Y.shape[0]), Y] = 1\n",
    "    return oh\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lib= np.load('../data/MNIST.npz')\n",
    "    X_train_3D = lib['X_train']\n",
    "    Y_train = lib['Y_train']\n",
    "    X_train = X_train_3D.reshape((X_train_3D.shape[0], -1))\n",
    "    Y_train_oh = one_hot(Y_train, 10)\n",
    "    X_valid_3D = lib['X_valid']\n",
    "    Y_valid = lib['Y_valid']\n",
    "    X_valid = X_valid_3D.reshape((X_valid_3D.shape[0], -1))\n",
    "    Y_valid_oh = one_hot(Y_valid, 10)\n",
    "\n",
    "    layer_sizes = [256, 256, 10]\n",
    "    activations = [tf.nn.tanh, tf.nn.tanh, None]\n",
    "    alpha = 0.01\n",
    "    iterations = 5000\n",
    "\n",
    "    np.random.seed(0)\n",
    "    save_path = train_mini_batch(X_train, Y_train_oh, X_valid, Y_valid_oh,\n",
    "                                 epochs=10, load_path='./graph.ckpt',\n",
    "                                 save_path='./model.ckpt')\n",
    "    print('Model saved in path: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61c4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
